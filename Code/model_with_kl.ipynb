{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, pairwise_distances\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_list(string):\n",
    "    return  [i[1:-1]for i in string[1:-1].split(', ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(df, col):\n",
    "    for i in range(len(df[col][0])):\n",
    "        df[f'{col}_{i}'] = [data[i] for data in df[col]]\n",
    "    df.drop(col, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data from .db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    conn = sqlite3.connect(\"../Data/yelpResData.db\")\n",
    "    conn.text_factory = lambda x: str(x, 'gb2312', 'ignore')\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Create Review DataFrame\n",
    "    cursor.execute(\n",
    "        \"SELECT reviewID, reviewerID, restaurantID, date, rating, usefulCount as reviewUsefulCount, reviewContent, flagged FROM review WHERE flagged in ('Y','N')\")\n",
    "    review_df = pd.DataFrame(cursor.fetchall(), columns=[column[0] for column in cursor.description])\n",
    "\n",
    "    # Create Reviewer DataFrame\n",
    "    cursor.execute(\"SELECT * FROM reviewer\")\n",
    "    reviewer_df = pd.DataFrame(cursor.fetchall(), columns=[column[0] for column in cursor.description])\n",
    "\n",
    "    # Create Restaurant DataFrame\n",
    "    cursor.execute(\"SELECT restaurantID, rating as restaurantRating FROM restaurant\")\n",
    "    restaurant_df = pd.DataFrame(cursor.fetchall(), columns=[column[0] for column in cursor.description])\n",
    "\n",
    "    # Merge all DataFrames\n",
    "    review_reviewer_df = review_df.merge(reviewer_df, on='reviewerID', how='inner')\n",
    "    df = review_reviewer_df.merge(restaurant_df, on='restaurantID', how='inner')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df):\n",
    "    # Removing \\n from date field\n",
    "    for i in range(len(df['date'])):\n",
    "        if df['date'][i][0] == '\\n':\n",
    "            df['date'][i] = df['date'][i][1:]\n",
    "\n",
    "    # Making yelpJoinDate Format Uniform\n",
    "    df['yelpJoinDate'] = df['yelpJoinDate'].apply(\n",
    "        lambda x: datetime.strftime(datetime.strptime(x, '%B %Y'), '01/%m/%Y'))\n",
    "\n",
    "    # Pre-processing Text Reviews\n",
    "    # Remove Stop Words\n",
    "    stop = stopwords.words('english')\n",
    "    df['reviewContent'] = df['reviewContent'].apply(\n",
    "        lambda x: ' '.join(word for word in x.split() if word not in stop))\n",
    "\n",
    "    # Remove Punctuations\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    df['reviewContent'] = df['reviewContent'].apply(\n",
    "        lambda x: ' '.join(word for word in tokenizer.tokenize(x)))\n",
    "\n",
    "    # Lowercase Words\n",
    "    df['reviewContent'] = df['reviewContent'].apply(\n",
    "        lambda x: x.lower())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df, N):\n",
    "    mnr_df1 = df[['reviewerID', 'date']].copy()\n",
    "    mnr_df2 = mnr_df1.groupby(by=['date', 'reviewerID']).size().reset_index(name='reviewPerDay')\n",
    "    mnr_df2['scaledReviewPerDay'] = mnr_df2['reviewPerDay'] / mnr_df2['reviewPerDay'].max()\n",
    "    mnr_df2.drop(columns=['reviewPerDay'], inplace=True)\n",
    "    df = df.merge(mnr_df2, on=['reviewerID', 'date'], how='inner')\n",
    "\n",
    "    # Review Length\n",
    "    df['reviewsLength'] = df['reviewContent'].apply(\n",
    "        lambda x: len(x.split()))\n",
    "\n",
    "    # Review Deviation\n",
    "    df['reviewsDeviation'] = abs(df['rating'] - df['restaurantRating']) / 4\n",
    "\n",
    "    # Maximum cosine similarity\n",
    "    review_data = df\n",
    "\n",
    "    res = OrderedDict()\n",
    "\n",
    "    # Iterate over data and create groups of reviewers\n",
    "    for row in review_data.iterrows():\n",
    "        if row[1].reviewerID in res:\n",
    "            res[row[1].reviewerID].append(row[1].reviewContent)\n",
    "        else:\n",
    "            res[row[1].reviewerID] = [row[1].reviewContent]\n",
    "\n",
    "    individual_reviewer = [{'reviewerID': k, 'reviewContent': v} for k, v in res.items()]\n",
    "    df2 = dict()\n",
    "    df2['reviewerID'] = pd.Series([])\n",
    "    df2['maximumContentSimilarity'] = pd.Series([])\n",
    "    vector = TfidfVectorizer(min_df=0)\n",
    "    count = -1\n",
    "    for reviewer_data in individual_reviewer:\n",
    "        count = count + 1\n",
    "        # Handle Null/single review gracefully -24-Apr-2019\n",
    "        try:\n",
    "            tfidf = vector.fit_transform(reviewer_data['reviewContent'])\n",
    "        except:\n",
    "            pass\n",
    "        cosine = 1 - pairwise_distances(tfidf, metric='cosine')\n",
    "\n",
    "        np.fill_diagonal(cosine, -np.inf)\n",
    "        max = cosine.max()\n",
    "\n",
    "        # To handle reviewier with just 1 review\n",
    "        if max == -np.inf:\n",
    "            max = 0\n",
    "        df2['reviewerID'][count] = reviewer_data['reviewerID']\n",
    "        df2['maximumContentSimilarity'][count] = max\n",
    "\n",
    "    df3 = pd.DataFrame(df2, columns=['reviewerID', 'maximumContentSimilarity'])\n",
    "\n",
    "    # left outer join on original datamatrix and cosine dataframe -24-Apr-2019\n",
    "    df = pd.merge(review_data, df3, on=\"reviewerID\", how=\"left\")\n",
    "\n",
    "    df.drop(index=np.where(pd.isnull(df))[0], axis=0, inplace=True)\n",
    "  \n",
    "    with open(\"../Data/top_word/top50_y_word.txt\", \"r\") as f:\n",
    "        fake_words = string_to_list(f.read())\n",
    "  \n",
    "    with open(\"../Data/top_word/top50_n_word.txt\", \"r\") as f:\n",
    "        non_fake_words = string_to_list(f.read())\n",
    "\n",
    "    fake_words = fake_words[:N]\n",
    "    non_fake_words = non_fake_words[:N]\n",
    "\n",
    "    # KL word count\n",
    "    fakeWordsCount = []\n",
    "    nonFakeWordsCount = []\n",
    "\n",
    "    for content in df['reviewContent']:\n",
    "        words = re.findall(r'\\b[A-Za-z][a-z]{2,9}\\b', content)\n",
    "        fakeCount = 0\n",
    "        nonFakeCount = 0\n",
    "        for word in words:\n",
    "            if word in fake_words:\n",
    "                fakeCount += 1\n",
    "            elif word in non_fake_words:\n",
    "                nonFakeCount += 1\n",
    "        fakeWordsCount.append(fakeCount)\n",
    "        nonFakeWordsCount.append(nonFakeCount)\n",
    "    \n",
    "    df['fakeWordsCount'] = fakeWordsCount\n",
    "    df['nonFakeWordsCount'] = nonFakeWordsCount\n",
    "    \n",
    "    # # KL one hot encoding\n",
    "    # fakeWordOneHot = []\n",
    "    # nonFakeWordOneHot = []\n",
    "\n",
    "    # for content in df['reviewContent']:\n",
    "    #     fakeOneHot = ''\n",
    "    #     nonFakeOneHot = ''\n",
    "    #     words = re.findall(r'\\b[A-Za-z][a-z]{2,9}\\b', content)\n",
    "\n",
    "    #     for word in fake_words:\n",
    "    #         if word in words:\n",
    "    #             fakeOneHot += '1'\n",
    "    #         else:\n",
    "    #             fakeOneHot += '0'\n",
    "\n",
    "    #     for word in non_fake_words:\n",
    "    #         if word in words:\n",
    "    #             nonFakeOneHot += '1'\n",
    "    #         else:\n",
    "    #             nonFakeOneHot += '0'\n",
    "                \n",
    "    #     fakeWordOneHot.append(fakeOneHot)\n",
    "    #     nonFakeWordOneHot.append(nonFakeOneHot)\n",
    "    \n",
    "    # df['fakeWordsOneHot'] = fakeWordOneHot\n",
    "    # # df['nonFakeWordsOneHot'] = nonFakeWordOneHot\n",
    "\n",
    "    # df = onehot(df, 'fakeWordsOneHot')\n",
    "    # # df = onehot(df, 'nonFakeWordsOneHot')\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_sampling(df):\n",
    "    print(\"Under-Sampling Data\")\n",
    "\n",
    "    sample_size = len(df[(df['flagged'] == 'Y')])\n",
    "\n",
    "    authentic_reviews_df = df[df['flagged'] == 'N']\n",
    "    fake_reviews_df = df[df['flagged'] == 'Y']\n",
    "\n",
    "    authentic_reviews_us_df = authentic_reviews_df.sample(sample_size)\n",
    "    under_sampled_df = pd.concat([authentic_reviews_us_df, fake_reviews_df], axis=0)\n",
    "\n",
    "    print(\"Under-Sampling Complete\")\n",
    "    return under_sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sampling(df):\n",
    "    print(\"Over-Sampling Data\")\n",
    "\n",
    "    sample_size = len(df[(df['flagged'] == 'N')])\n",
    "\n",
    "    authentic_reviews_df = df[df['flagged'] == 'N']\n",
    "    fake_reviews_df = df[df['flagged'] == 'Y']\n",
    "\n",
    "    fake_reviews_os_df = fake_reviews_df.sample(sample_size, replace=True)\n",
    "    over_sampled_df = pd.concat([authentic_reviews_df, fake_reviews_os_df], axis=0)\n",
    "\n",
    "    print(\"Over-Sampling Complete\")\n",
    "    return over_sampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes, title=None, cmap=plt.cm.Blues):\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes,\n",
    "           yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_learning(df, model, algorithm):\n",
    "    df = df.copy()\n",
    "    print(\"Training \"+algorithm+\" Model\")\n",
    "    labels = df['flagged']\n",
    "\n",
    "    df.drop(['reviewID', 'reviewerID', 'restaurantID', 'date', 'name', 'location', 'yelpJoinDate', 'flagged',\n",
    "             'reviewContent', 'restaurantRating'], axis=1, inplace=True)\n",
    "\n",
    "    train_data, test_data, train_label, test_label = train_test_split(df, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "    # param_grid = {\n",
    "    #     'n_estimators': [10, 500],\n",
    "    #     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    #     'max_depth': [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],\n",
    "    #     'criterion': ['gini', 'entropy']\n",
    "    # }\n",
    "    # grid_clf_acc = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
    "    #\n",
    "    # grid_clf_acc.fit(train_data, train_label)\n",
    "\n",
    "    model.fit(train_data, train_label)\n",
    "    predicted_labels = model.predict(test_data)\n",
    "\n",
    "    # print('Best Params : ', grid_clf_acc.best_params_)\n",
    "    print(algorithm + ' Model Results')\n",
    "    print('--' * 20)\n",
    "    print('Accuracy Score : ' + str(accuracy_score(test_label, predicted_labels)))\n",
    "    print('Precision Score : ' + str(precision_score(test_label, predicted_labels, pos_label=\"Y\")))\n",
    "    print('Recall Score : ' + str(recall_score(test_label, predicted_labels, pos_label=\"Y\")))\n",
    "    print('F1 Score : ' + str(f1_score(test_label, predicted_labels, pos_label=\"Y\")))\n",
    "    print('Confusion Matrix : \\n' + str(confusion_matrix(test_label, predicted_labels)))\n",
    "    plot_confusion_matrix(test_label, predicted_labels, classes=['N', 'Y'],\n",
    "                          title=algorithm + ' Confusion Matrix').show()\n",
    "\n",
    "    return test_label, predicted_labels, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semi_supervised_learning(df, model, algorithm, threshold=0.8, iterations=40):\n",
    "    df = df.copy()\n",
    "    print(\"Training \"+algorithm+\" Model\")\n",
    "    labels = df['flagged']\n",
    "\n",
    "    df.drop(['reviewID', 'reviewerID', 'restaurantID', 'date', 'name', 'location', 'yelpJoinDate', 'flagged', 'restaurantRating'], axis=1, inplace=True)\n",
    "\n",
    "    train_data, test_data, train_label, test_label = train_test_split(df, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "    test_review_content = test_data['reviewContent']\n",
    "    train_data.drop(['reviewContent'], axis=1, inplace=True)\n",
    "    test_data.drop(['reviewContent'], axis=1, inplace=True)\n",
    "    \n",
    "    test_data_copy = test_data.copy()\n",
    "    test_label_copy = test_label.copy()\n",
    "\n",
    "    all_labeled = False\n",
    "\n",
    "    current_iteration = 0\n",
    "\n",
    "    # param_grid = {\n",
    "    #     'n_estimators': [10, 500],\n",
    "    #     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    #     'max_depth': [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],\n",
    "    #     'criterion': ['gini', 'entropy']\n",
    "    # }\n",
    "    # grid_clf_acc = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
    "    #\n",
    "    # grid_clf_acc.fit(train_data, train_label)\n",
    "\n",
    "    pbar = tqdm(total=iterations)\n",
    "\n",
    "    while not all_labeled and (current_iteration < iterations):\n",
    "        # print(\"Before train data length : \", len(train_data))\n",
    "        # print(\"Before test data length : \", len(test_data))\n",
    "        current_iteration += 1\n",
    "        model.fit(train_data, train_label)\n",
    "\n",
    "        probabilities = model.predict_proba(test_data)\n",
    "        pseudo_labels = model.predict(test_data)\n",
    "\n",
    "        indices = np.argwhere(probabilities > threshold)\n",
    "\n",
    "        # print(\"rows above threshold : \", len(indices))\n",
    "        for item in indices:\n",
    "            train_data.loc[test_data.index[item[0]]] = test_data.iloc[item[0]]\n",
    "            train_label.loc[test_data.index[item[0]]] = pseudo_labels[item[0]]\n",
    "        test_data.drop(test_data.index[indices[:, 0]], inplace=True)\n",
    "        test_label.drop(test_label.index[indices[:, 0]], inplace=True)\n",
    "        # print(\"After train data length : \", len(train_data))\n",
    "        # print(\"After test data length : \", len(test_data))\n",
    "        print(\"--\" * 20)\n",
    "\n",
    "        if len(test_data) == 0:\n",
    "            print(\"Exiting loop\")\n",
    "            all_labeled = True\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    predicted_labels = model.predict(test_data_copy)\n",
    "\n",
    "    # print('Best Params : ', grid_clf_acc.best_params_)\n",
    "    print(algorithm + ' Model Results')\n",
    "    print('--' * 20)\n",
    "    print('Accuracy Score : ' + str(accuracy_score(test_label_copy, predicted_labels)))\n",
    "    print('Precision Score : ' + str(precision_score(test_label_copy, predicted_labels, pos_label=\"Y\")))\n",
    "    print('Recall Score : ' + str(recall_score(test_label_copy, predicted_labels, pos_label=\"Y\")))\n",
    "    print('F1 Score : ' + str(f1_score(test_label_copy, predicted_labels, pos_label=\"Y\")))\n",
    "    print('Confusion Matrix : \\n' + str(confusion_matrix(test_label_copy, predicted_labels)))\n",
    "    plot_confusion_matrix(test_label_copy, predicted_labels, classes=['N', 'Y'],\n",
    "                          title=algorithm + ' Confusion Matrix').show()\n",
    "\n",
    "    results = test_data_copy.copy()\n",
    "    results['reviewContent'] = test_review_content\n",
    "    results['flagged'] = test_label_copy\n",
    "    results['predicted'] = predicted_labels\n",
    "\n",
    "    return model, results\n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Um_25\\AppData\\Local\\Temp\\ipykernel_1840\\3075169008.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date'][i] = df['date'][i][1:]\n",
      "C:\\Users\\Um_25\\AppData\\Local\\Temp\\ipykernel_1840\\2252993440.py:29: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  df2['reviewerID'] = pd.Series([])\n",
      "C:\\Users\\Um_25\\AppData\\Local\\Temp\\ipykernel_1840\\2252993440.py:30: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  df2['maximumContentSimilarity'] = pd.Series([])\n"
     ]
    }
   ],
   "source": [
    "df = load_data()\n",
    "df = data_cleaning(df)\n",
    "df = feature_engineering(df, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reviewID', 'reviewerID', 'restaurantID', 'date', 'rating',\n",
       "       'reviewUsefulCount', 'reviewContent', 'flagged', 'name', 'location',\n",
       "       'yelpJoinDate', 'friendCount', 'reviewCount', 'firstCount',\n",
       "       'usefulCount', 'coolCount', 'funnyCount', 'complimentCount', 'tipCount',\n",
       "       'fanCount', 'restaurantRating', 'scaledReviewPerDay', 'reviewsLength',\n",
       "       'reviewsDeviation', 'maximumContentSimilarity', 'fakeWordsCount',\n",
       "       'nonFakeWordsCount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under-Sampling Data\n",
      "Under-Sampling Complete\n"
     ]
    }
   ],
   "source": [
    "under_sampled_df = under_sampling(df)\n",
    "under_sampled_df.reset_index(drop=True, inplace=True)\n",
    "# under_sampled_df.to_csv('../Data/under_sampled_KL_df.csv', index=False)\n",
    "# under_sampled_df = pd.read_csv('../Data/under_sampled_KL_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over-Sampling Data\n",
      "Over-Sampling Complete\n"
     ]
    }
   ],
   "source": [
    "over_sampled_df = over_sampling(df)\n",
    "over_sampled_df.reset_index(drop=True, inplace=True)\n",
    "# over_sampled_df.to_csv('../Data/over_sampled_KL_df.csv', index=False)\n",
    "# over_sampled_df = pd.read_csv('../Data/over_sampled_KL_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train DF Columns\n",
    "- rating = comment rating **<span style=\"color:CornflowerBlue\">(raw review file)</span>**\n",
    "- reviewUsefulCount = number of user's review useful count raw **<span style=\"color:CornflowerBlue\">(count form raw review file)</span>** \n",
    "- friendCount = number of user's friend raw **<span style=\"color:CornflowerBlue\">(join form user file)</span>** \n",
    "- reviewCount = number of user's review count raw **<span style=\"color:CornflowerBlue\">(join form user file)</span>** \n",
    "- firstCount = number of user's first comment raw **<span style=\"color:CornflowerBlue\">(count form raw review file)</span>** \n",
    "- usefulCount = number of comment's useful count raw **<span style=\"color:CornflowerBlue\">(raw review file)</span>** \n",
    "- coolCount = number of comment's cool count raw **<span style=\"color:CornflowerBlue\">(raw review file)</span>** \n",
    "- funnyCount = number of comment's funny count raw **<span style=\"color:CornflowerBlue\">(raw review file)</span>** \n",
    "- complimentCount = review's compliment count raw **<span style=\"color:CornflowerBlue\">(join form tip file)</span>** \n",
    "- tipCount = user's tip count raw **<span style=\"color:CornflowerBlue\">(join form tip file)</span>** \n",
    "- fanCount = number of user's fan raw **<span style=\"color:CornflowerBlue\">(join form user file)</span>** \n",
    "- scaledReviewPerDay = scaled review per day raw **<span style=\"color:CornflowerBlue\">(calculate from raw review file)</span>** \n",
    "- reviewsLength = review length raw **<span style=\"color:CornflowerBlue\">(calculate from raw review file)</span>** \n",
    "- reviewsDeviation = store rating - user rating raw **<span style=\"color:CornflowerBlue\">(calculate form businees and reviews file)</span>**\n",
    "- maximumContentSimilarity = maximun content similarity raw **<span style=\"color:CornflowerBlue\">(calculate from raw review file)</span>** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42, criterion='entropy', max_depth=14, max_features='auto',\n",
    "                            n_estimators=500)\n",
    "nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semi_supervised_learning(df, model=rf, threshold=0.7, iterations=15, algorithm='Random Forest')\n",
    "# semi_supervised_learning(df, model=nb, threshold=0.7, iterations=15, algorithm='Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semi_supervised_learning(under_sampled_df, model=rf, threshold=0.7, iterations=15, algorithm='Random Forest')\n",
    "# semi_supervised_learning(under_sampled_df, model=nb, threshold=0.7, iterations=15, algorithm='Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [01:16<17:52, 76.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [01:36<09:22, 43.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [01:59<06:49, 34.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [02:17<05:06, 27.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [02:34<03:57, 23.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [02:49<03:05, 20.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [03:05<02:33, 19.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [03:20<02:05, 17.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [03:38<01:47, 17.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [03:53<01:25, 17.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [04:08<01:05, 16.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [04:22<00:47, 15.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [04:39<00:32, 16.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [04:55<00:16, 16.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:11<00:00, 20.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Results\n",
      "----------------------------------------\n",
      "Accuracy Score : 0.9295489591364687\n",
      "Precision Score : 0.8889275160785677\n",
      "Recall Score : 0.9823280829811756\n",
      "F1 Score : 0.9332968336527055\n",
      "Confusion Matrix : \n",
      "[[4531  639]\n",
      " [  92 5114]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, results = semi_supervised_learning(over_sampled_df, model=rf, threshold=0.7, iterations=15, algorithm='Random Forest')\n",
    "# semi_supervised_learning(over_sampled_df, model=nb, threshold=0.7, iterations=15, algorithm='Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('../Data/results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (tags/v3.9.12:b28265d, Mar 23 2022, 23:52:46) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d2032d7104da15a9d10fd1a2c136158f111ee2ad9d0f9c669774920547ee53a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
