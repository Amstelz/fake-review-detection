{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, pairwise_distances\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from pythainlp.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df):\n",
    "    # Removing \\n from date field\n",
    "    for i in range(len(df['date'])):\n",
    "        if df['date'][i][0] == '\\n':\n",
    "            df['date'][i] = df['date'][i][1:]\n",
    "\n",
    "    # Making yelpJoinDate Format Uniform\n",
    "    df['yelpJoinDate'] = df['yelpJoinDate'].apply(\n",
    "        lambda x: datetime.strftime(datetime.strptime(x, '%B %Y'), '01/%m/%Y'))\n",
    "\n",
    "    # Pre-processing Text Reviews\n",
    "    # Remove Symbols\n",
    "    df['reviewContent'] = df['reviewContent'].apply(\n",
    "        lambda x: ''.join(char for char in str(x) if char not in '!\"#$&\\'()*.:;<=>?@[\\\\]^_`{|}~'))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning_shopee(df):\n",
    "    # Removing \\n from date field\n",
    "    for i in range(len(df['date'])):\n",
    "        if df['date'][i][0] == '\\n':\n",
    "            df['date'][i] = df['date'][i][1:]\n",
    "\n",
    "    # Pre-processing Text Reviews\n",
    "    # Remove Symbols\n",
    "    df['reviewContent'] = df['reviewContent'].apply(\n",
    "        lambda x: ''.join(char for char in str(x) if char not in '!\"#$&\\'()*.:;<=>?@[\\\\]^_`{|}~'))\n",
    "    \n",
    "    df['reviewContent'] = df['reviewContent'].apply(\n",
    "        lambda x: x.replace('\\n', ' '))\n",
    "\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", flags=re.UNICODE)\n",
    "\n",
    "    df['reviewContent'] = df['reviewContent'].apply(\n",
    "        lambda x: emoji_pattern.sub(r'', x))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    mnr_df1 = df[['reviewerID', 'date']].copy()\n",
    "    mnr_df2 = mnr_df1.groupby(by=['date', 'reviewerID']).size().reset_index(name='reviewPerDay')\n",
    "    mnr_df2['scaledReviewPerDay'] = mnr_df2['reviewPerDay'] / mnr_df2['reviewPerDay'].max()\n",
    "    mnr_df2.drop(columns=['reviewPerDay'], inplace=True)\n",
    "    df = df.merge(mnr_df2, on=['reviewerID', 'date'], how='inner')\n",
    "\n",
    "    # Review Length\n",
    "    df['reviewsLength'] = df['reviewContent'].apply(\n",
    "        lambda x: len(word_tokenize(x, engine=\"newmm\")))\n",
    "\n",
    "    # Review Deviation\n",
    "    df['reviewsDeviation'] = abs(df['rating'] - df['restaurantRating']) / 4\n",
    "\n",
    "    # Maximum cosine similarity\n",
    "    review_data = df\n",
    "\n",
    "    res = OrderedDict()\n",
    "\n",
    "    # Iterate over data and create groups of reviewers\n",
    "    for row in review_data.iterrows():\n",
    "        if row[1].reviewerID in res:\n",
    "            res[row[1].reviewerID].append(row[1].reviewContent)\n",
    "        else:\n",
    "            res[row[1].reviewerID] = [row[1].reviewContent]\n",
    "\n",
    "    individual_reviewer = [{'reviewerID': k, 'reviewContent': v} for k, v in res.items()]\n",
    "    df2 = dict()\n",
    "    df2['reviewerID'] = pd.Series([])\n",
    "    df2['maximumContentSimilarity'] = pd.Series([])\n",
    "    vector = TfidfVectorizer(min_df=0)\n",
    "    count = -1\n",
    "    for reviewer_data in individual_reviewer:\n",
    "        count = count + 1\n",
    "        # Handle Null/single review gracefully -24-Apr-2019\n",
    "        try:\n",
    "            tfidf = vector.fit_transform(reviewer_data['reviewContent'])\n",
    "        except:\n",
    "            pass\n",
    "        cosine = 1 - pairwise_distances(tfidf, metric='cosine')\n",
    "\n",
    "        np.fill_diagonal(cosine, -np.inf)\n",
    "        max = cosine.max()\n",
    "\n",
    "        # To handle reviewier with just 1 review\n",
    "        if max == -np.inf:\n",
    "            max = 0\n",
    "        df2['reviewerID'][count] = reviewer_data['reviewerID']\n",
    "        df2['maximumContentSimilarity'][count] = max\n",
    "\n",
    "    df3 = pd.DataFrame(df2, columns=['reviewerID', 'maximumContentSimilarity'])\n",
    "\n",
    "    # left outer join on original datamatrix and cosine dataframe -24-Apr-2019\n",
    "    df = pd.merge(review_data, df3, on=\"reviewerID\", how=\"left\")\n",
    "\n",
    "    df.drop(index=np.where(pd.isnull(df))[0], axis=0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_sampling(df):\n",
    "    print(\"Under-Sampling Data\")\n",
    "\n",
    "    sample_size = len(df[(df['flagged'] == 'Y')])\n",
    "\n",
    "    authentic_reviews_df = df[df['flagged'] == 'N']\n",
    "    fake_reviews_df = df[df['flagged'] == 'Y']\n",
    "\n",
    "    authentic_reviews_us_df = authentic_reviews_df.sample(sample_size)\n",
    "    under_sampled_df = pd.concat([authentic_reviews_us_df, fake_reviews_df], axis=0)\n",
    "\n",
    "    print(\"Under-Sampling Complete\")\n",
    "    return under_sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sampling(df):\n",
    "    print(\"Over-Sampling Data\")\n",
    "\n",
    "    sample_size = len(df[(df['flagged'] == 'N')])\n",
    "\n",
    "    authentic_reviews_df = df[df['flagged'] == 'N']\n",
    "    fake_reviews_df = df[df['flagged'] == 'Y']\n",
    "\n",
    "    fake_reviews_os_df = fake_reviews_df.sample(sample_size, replace=True)\n",
    "    over_sampled_df = pd.concat([authentic_reviews_df, fake_reviews_os_df], axis=0)\n",
    "\n",
    "    print(\"Over-Sampling Complete\")\n",
    "    return over_sampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes, title=None, cmap=plt.cm.Blues):\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes,\n",
    "           yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_learning(df, model, algorithm):\n",
    "    df = df.copy()\n",
    "    print(\"Training \"+algorithm+\" Model\")\n",
    "    labels = df['flagged']\n",
    "\n",
    "    df.drop(['reviewID', 'reviewerID', 'restaurantID', 'date', 'name', 'location', 'yelpJoinDate', 'flagged',\n",
    "             'reviewContent', 'restaurantRating'], axis=1, inplace=True)\n",
    "\n",
    "    train_data, test_data, train_label, test_label = train_test_split(df, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "    # param_grid = {\n",
    "    #     'n_estimators': [10, 500],\n",
    "    #     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    #     'max_depth': [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],\n",
    "    #     'criterion': ['gini', 'entropy']\n",
    "    # }\n",
    "    # grid_clf_acc = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
    "    #\n",
    "    # grid_clf_acc.fit(train_data, train_label)\n",
    "\n",
    "    model.fit(train_data, train_label)\n",
    "    predicted_labels = model.predict(test_data)\n",
    "\n",
    "    # print('Best Params : ', grid_clf_acc.best_params_)\n",
    "    print(algorithm + ' Model Results')\n",
    "    print('--' * 20)\n",
    "    print('Accuracy Score : ' + str(accuracy_score(test_label, predicted_labels)))\n",
    "    print('Precision Score : ' + str(precision_score(test_label, predicted_labels, pos_label=\"Y\")))\n",
    "    print('Recall Score : ' + str(recall_score(test_label, predicted_labels, pos_label=\"Y\")))\n",
    "    print('F1 Score : ' + str(f1_score(test_label, predicted_labels, pos_label=\"Y\")))\n",
    "    print('Confusion Matrix : \\n' + str(confusion_matrix(test_label, predicted_labels)))\n",
    "    plot_confusion_matrix(test_label, predicted_labels, classes=['N', 'Y'],\n",
    "                          title=algorithm + ' Confusion Matrix').show()\n",
    "\n",
    "    return test_label, predicted_labels, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semi_supervised_learning(df, model, algorithm, threshold=0.8, iterations=40):\n",
    "    df = df.copy()\n",
    "    print(\"Training \"+algorithm+\" Model\")\n",
    "    labels = df['flagged']\n",
    "\n",
    "    # df.drop(['reviewID', 'reviewerID', 'restaurantID', 'date', 'name', 'location', 'yelpJoinDate', 'flagged', 'restaurantRating'], axis=1, inplace=True)\n",
    "    df.drop(['reviewID', 'reviewerID', 'restaurantID', 'date', 'name', 'location', 'yelpJoinDate',\n",
    "             'flagged', 'restaurantRating', 'usefulCount', 'coolCount', 'funnyCount',\n",
    "             'complimentCount', 'tipCount', 'fanCount'], axis=1, inplace=True)\n",
    "\n",
    "    train_data, test_data, train_label, test_label = train_test_split(df, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "    test_review_content = test_data['reviewContent']\n",
    "    train_data.drop(['reviewContent'], axis=1, inplace=True)\n",
    "    test_data.drop(['reviewContent'], axis=1, inplace=True)\n",
    "    \n",
    "    test_data_copy = test_data.copy()\n",
    "    test_label_copy = test_label.copy()\n",
    "\n",
    "    all_labeled = False\n",
    "\n",
    "    current_iteration = 0\n",
    "\n",
    "    # param_grid = {\n",
    "    #     'n_estimators': [10, 500],\n",
    "    #     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    #     'max_depth': [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],\n",
    "    #     'criterion': ['gini', 'entropy']\n",
    "    # }\n",
    "    # grid_clf_acc = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
    "    #\n",
    "    # grid_clf_acc.fit(train_data, train_label)\n",
    "\n",
    "    pbar = tqdm(total=iterations)\n",
    "\n",
    "    while not all_labeled and (current_iteration < iterations):\n",
    "        # print(\"Before train data length : \", len(train_data))\n",
    "        # print(\"Before test data length : \", len(test_data))\n",
    "        current_iteration += 1\n",
    "        model.fit(train_data, train_label)\n",
    "\n",
    "        probabilities = model.predict_proba(test_data)\n",
    "        pseudo_labels = model.predict(test_data)\n",
    "\n",
    "        indices = np.argwhere(probabilities > threshold)\n",
    "\n",
    "        # print(\"rows above threshold : \", len(indices))\n",
    "        for item in indices:\n",
    "            train_data.loc[test_data.index[item[0]]] = test_data.iloc[item[0]]\n",
    "            train_label.loc[test_data.index[item[0]]] = pseudo_labels[item[0]]\n",
    "        test_data.drop(test_data.index[indices[:, 0]], inplace=True)\n",
    "        test_label.drop(test_label.index[indices[:, 0]], inplace=True)\n",
    "        # print(\"After train data length : \", len(train_data))\n",
    "        # print(\"After test data length : \", len(test_data))\n",
    "        print(\"--\" * 20)\n",
    "\n",
    "        if len(test_data) == 0:\n",
    "            print(\"Exiting loop\")\n",
    "            all_labeled = True\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    predicted_labels = model.predict(test_data_copy)\n",
    "\n",
    "    # print('Best Params : ', grid_clf_acc.best_params_)\n",
    "    print(algorithm + ' Model Results')\n",
    "    print('--' * 20)\n",
    "    print('Accuracy Score : ' + str(accuracy_score(test_label_copy, predicted_labels)))\n",
    "    print('Precision Score : ' + str(precision_score(test_label_copy, predicted_labels, pos_label=\"Y\")))\n",
    "    print('Recall Score : ' + str(recall_score(test_label_copy, predicted_labels, pos_label=\"Y\")))\n",
    "    print('F1 Score : ' + str(f1_score(test_label_copy, predicted_labels, pos_label=\"Y\")))\n",
    "    print('Confusion Matrix : \\n' + str(confusion_matrix(test_label_copy, predicted_labels)))\n",
    "    plot_confusion_matrix(test_label_copy, predicted_labels, classes=['N', 'Y'],\n",
    "                          title=algorithm + ' Confusion Matrix').show()\n",
    "\n",
    "    results = test_data_copy.copy()\n",
    "    results['reviewContent'] = test_review_content\n",
    "    results['flagged'] = test_label_copy\n",
    "    results['predicted'] = predicted_labels\n",
    "\n",
    "    return model, results\n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../Data/raw_thai_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('../Data/shopee_follower.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['date'] = df2['date'].astype('datetime64[ns]')\n",
    "df2['date'] = df2['date'].dt.strftime(r'%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(columns=['flagged', 'name', 'location', 'yelpJoinDate', 'usefulCount', 'coolCount', 'funnyCount', 'complimentCount', 'tipCount', 'fanCount'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = list(df1.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[col_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Um_25\\AppData\\Local\\Temp\\ipykernel_66708\\1301984762.py:29: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  df2['reviewerID'] = pd.Series([])\n",
      "C:\\Users\\Um_25\\AppData\\Local\\Temp\\ipykernel_66708\\1301984762.py:30: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  df2['maximumContentSimilarity'] = pd.Series([])\n"
     ]
    }
   ],
   "source": [
    "df = data_cleaning_shopee(df2)\n",
    "df = feature_engineering(df)\n",
    "df.to_csv('../Data/thai_shopee_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/thai_shopee_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df.drop(['reviewID', 'reviewerID', 'restaurantID', 'date', 'reviewContent', 'restaurantRating'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in test_df.columns:\n",
    "    test_df[col] = test_df[col].apply(lambda x: float(str(x).split('k')[0]) * 1000 if str(x)[-1] == 'k' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewUsefulCount</th>\n",
       "      <th>friendCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>firstCount</th>\n",
       "      <th>scaledReviewPerDay</th>\n",
       "      <th>reviewsLength</th>\n",
       "      <th>reviewsDeviation</th>\n",
       "      <th>maximumContentSimilarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>93</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>37</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>83</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>74</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>24</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>89</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>33</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>186</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>56</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>30</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1134 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating  reviewUsefulCount friendCount  reviewCount  firstCount  \\\n",
       "0          5                6.0         7.0            1           0   \n",
       "1          5               18.0        60.0            1           0   \n",
       "2          5               16.0        36.0            1           1   \n",
       "3          5               12.0        11.0            1           0   \n",
       "4          5                2.0        10.0            1           0   \n",
       "...      ...                ...         ...          ...         ...   \n",
       "1129       5               10.0           2            1           0   \n",
       "1130       5                3.0          26            1           0   \n",
       "1131       5               11.0         102            1           0   \n",
       "1132       5               12.0         186            1           0   \n",
       "1133       5                1.0      2000.0            1           0   \n",
       "\n",
       "      scaledReviewPerDay  reviewsLength  reviewsDeviation  \\\n",
       "0                   0.25             93             0.025   \n",
       "1                   0.25             37             0.025   \n",
       "2                   0.25             83             0.025   \n",
       "3                   0.25             74             0.025   \n",
       "4                   0.25             24             0.025   \n",
       "...                  ...            ...               ...   \n",
       "1129                0.25             89             0.025   \n",
       "1130                0.25             25             0.025   \n",
       "1131                0.25             33             0.025   \n",
       "1132                0.25             56             0.025   \n",
       "1133                0.25             30             0.025   \n",
       "\n",
       "      maximumContentSimilarity  \n",
       "0                          0.0  \n",
       "1                          0.0  \n",
       "2                          0.0  \n",
       "3                          0.0  \n",
       "4                          0.0  \n",
       "...                        ...  \n",
       "1129                       0.0  \n",
       "1130                       0.0  \n",
       "1131                       0.0  \n",
       "1132                       0.0  \n",
       "1133                       0.0  \n",
       "\n",
       "[1134 rows x 9 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train DF Columns\n",
    "- rating = comment rating **<span style=\"color:CornflowerBlue\">(raw review file)</span>**\n",
    "- reviewUsefulCount = number of user's review useful count raw **<span style=\"color:CornflowerBlue\">(count form raw review file)</span>** \n",
    "- friendCount = number of user's friend raw **<span style=\"color:CornflowerBlue\">(join form user file)</span>** \n",
    "- reviewCount = number of user's review count raw **<span style=\"color:CornflowerBlue\">(join form user file)</span>** \n",
    "- firstCount = number of user's first comment raw **<span style=\"color:CornflowerBlue\">(count form raw review file)</span>** \n",
    "- scaledReviewPerDay = scaled review per day raw **<span style=\"color:CornflowerBlue\">(calculate from raw review file)</span>** \n",
    "- reviewsLength = review length raw **<span style=\"color:CornflowerBlue\">(calculate from raw review file)</span>** \n",
    "- reviewsDeviation = store rating - user rating raw **<span style=\"color:CornflowerBlue\">(calculate form businees and reviews file)</span>**\n",
    "- maximumContentSimilarity = maximun content similarity raw **<span style=\"color:CornflowerBlue\">(calculate from raw review file)</span>** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewUsefulCount</th>\n",
       "      <th>friendCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>firstCount</th>\n",
       "      <th>scaledReviewPerDay</th>\n",
       "      <th>reviewsLength</th>\n",
       "      <th>reviewsDeviation</th>\n",
       "      <th>maximumContentSimilarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>93</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>37</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>83</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>74</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>24</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>89</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>33</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>186</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>56</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>30</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1134 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating  reviewUsefulCount friendCount  reviewCount  firstCount  \\\n",
       "0          5                6.0         7.0            1           0   \n",
       "1          5               18.0        60.0            1           0   \n",
       "2          5               16.0        36.0            1           1   \n",
       "3          5               12.0        11.0            1           0   \n",
       "4          5                2.0        10.0            1           0   \n",
       "...      ...                ...         ...          ...         ...   \n",
       "1129       5               10.0           2            1           0   \n",
       "1130       5                3.0          26            1           0   \n",
       "1131       5               11.0         102            1           0   \n",
       "1132       5               12.0         186            1           0   \n",
       "1133       5                1.0      2000.0            1           0   \n",
       "\n",
       "      scaledReviewPerDay  reviewsLength  reviewsDeviation  \\\n",
       "0                   0.25             93             0.025   \n",
       "1                   0.25             37             0.025   \n",
       "2                   0.25             83             0.025   \n",
       "3                   0.25             74             0.025   \n",
       "4                   0.25             24             0.025   \n",
       "...                  ...            ...               ...   \n",
       "1129                0.25             89             0.025   \n",
       "1130                0.25             25             0.025   \n",
       "1131                0.25             33             0.025   \n",
       "1132                0.25             56             0.025   \n",
       "1133                0.25             30             0.025   \n",
       "\n",
       "      maximumContentSimilarity  \n",
       "0                          0.0  \n",
       "1                          0.0  \n",
       "2                          0.0  \n",
       "3                          0.0  \n",
       "4                          0.0  \n",
       "...                        ...  \n",
       "1129                       0.0  \n",
       "1130                       0.0  \n",
       "1131                       0.0  \n",
       "1132                       0.0  \n",
       "1133                       0.0  \n",
       "\n",
       "[1134 rows x 9 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../Model/finalized_model.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['flag'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../Data/thai_shopee_result_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d2032d7104da15a9d10fd1a2c136158f111ee2ad9d0f9c669774920547ee53a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
