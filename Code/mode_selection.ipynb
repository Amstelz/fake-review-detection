{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "import Utils.dataframe as dataframe_helper\n",
    "import Utils.learning as learning\n",
    "import mlflow\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='../mlruns/746529752663207522', creation_time=1677145153271, experiment_id='746529752663207522', last_update_time=1677145153271, lifecycle_stage='active', name='Count By Word Model', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = \"Count By Word Model\"\n",
    "pd.set_option('display.max_columns', None)\n",
    "mlflow.set_tracking_uri(\"../mlruns\")\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering_one_hot(df:pd.DataFrame, N:int = None) -> pd.DataFrame:\n",
    "    with open(\"../Data/top_word/top_fake_word.txt\", \"r\") as f:\n",
    "        fake_words = dataframe_helper.string_to_list(f.read())\n",
    "  \n",
    "    with open(\"../Data/top_word/top_genuine_word.txt\", \"r\") as f:\n",
    "        non_fake_words = dataframe_helper.string_to_list(f.read())\n",
    "\n",
    "    fake_words = fake_words[:N]\n",
    "    non_fake_words = non_fake_words[:N]\n",
    "        \n",
    "    # KL one hot encoding\n",
    "    fakeWordOneHot = []\n",
    "    nonFakeWordOneHot = []\n",
    "\n",
    "    for content in df['reviewContent']:\n",
    "        fakeOneHot = ''\n",
    "        nonFakeOneHot = ''\n",
    "        words = re.findall(r'\\b[A-Za-z][a-z]{2,9}\\b', content)\n",
    "\n",
    "        for word in fake_words:\n",
    "            if word in words:\n",
    "                fakeOneHot += '1'\n",
    "            else:\n",
    "                fakeOneHot += '0'\n",
    "\n",
    "        for word in non_fake_words:\n",
    "            if word in words:\n",
    "                nonFakeOneHot += '1'\n",
    "            else:\n",
    "                nonFakeOneHot += '0'\n",
    "                \n",
    "        fakeWordOneHot.append(fakeOneHot)\n",
    "        nonFakeWordOneHot.append(nonFakeOneHot)\n",
    "    \n",
    "    result = pd.DataFrame()\n",
    "    result['fakeWordsOneHot'] = fakeWordOneHot\n",
    "    result['nonFakeWordsOneHot'] = nonFakeWordOneHot\n",
    "\n",
    "    result = dataframe_helper.onehot(result, 'fakeWordsOneHot', fake_words, 'fake')\n",
    "    result = dataframe_helper.onehot(result, 'nonFakeWordsOneHot', non_fake_words, 'non fake')\n",
    "    \n",
    "    result['reviewContent'] = df['reviewContent']\n",
    "    result['flagged'] = df['flagged']\n",
    "\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering_one_hot_cvect(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    with open(\"../Data/top_word/word_from_cVect.txt\", \"r\") as f:\n",
    "        bag_of_words = dataframe_helper.string_to_list(f.read())\n",
    "  \n",
    "    # KL one hot encoding\n",
    "    WordOneHot = []\n",
    "\n",
    "    for content in df['reviewContent']:\n",
    "        oneHot = ''\n",
    "        words = re.findall(r'\\b[A-Za-z][a-z]{2,9}\\b', content)\n",
    "\n",
    "        for word in bag_of_words:\n",
    "            if word in words:\n",
    "                oneHot += '1'\n",
    "            else:\n",
    "                oneHot += '0'\n",
    "                \n",
    "        WordOneHot.append(oneHot)\n",
    "    \n",
    "    result = pd.DataFrame()\n",
    "    result['WordsOneHot'] = WordOneHot\n",
    "\n",
    "    result = dataframe_helper.onehot(result, 'WordsOneHot', bag_of_words, '')\n",
    "    \n",
    "    result['reviewContent'] = df['reviewContent']\n",
    "    result['flagged'] = df['flagged']\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering_word_count(df:pd.DataFrame, N:int = None) -> pd.DataFrame:\n",
    "    with open(\"../Data/top_word/top_fake_word.txt\", \"r\") as f:\n",
    "        fake_words = dataframe_helper.string_to_list(f.read())\n",
    "  \n",
    "    with open(\"../Data/top_word/top_genuine_word.txt\", \"r\") as f:\n",
    "        non_fake_words = dataframe_helper.string_to_list(f.read())\n",
    "\n",
    "    fake_words = fake_words[:N]\n",
    "    non_fake_words = non_fake_words[:N]\n",
    "        \n",
    "    # KL word count\n",
    "    fakeWordsCount = []\n",
    "    nonFakeWordsCount = []\n",
    "\n",
    "    for content in df['reviewContent']:\n",
    "        words = re.findall(r'\\b[A-Za-z][a-z]{2,9}\\b', content)\n",
    "        fakeCount = 0\n",
    "        nonFakeCount = 0\n",
    "        for word in words:\n",
    "            if word in fake_words:\n",
    "                fakeCount += 1\n",
    "            elif word in non_fake_words:\n",
    "                nonFakeCount += 1\n",
    "        fakeWordsCount.append(fakeCount)\n",
    "        nonFakeWordsCount.append(nonFakeCount)\n",
    "\n",
    "    result = pd.DataFrame()\n",
    "    result['fakeWordsCount'] = fakeWordsCount\n",
    "    result['nonFakeWordsCount'] = nonFakeWordsCount\n",
    "    result['reviewContent'] = df['reviewContent']\n",
    "    result['flagged'] = df['flagged']\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering_count_by_word(df:pd.DataFrame, N:int = None) -> pd.DataFrame:\n",
    "    with open(\"../Data/top_word/top_fake_word.txt\", \"r\") as f:\n",
    "        fake_words = dataframe_helper.string_to_list(f.read())\n",
    "  \n",
    "    with open(\"../Data/top_word/top_genuine_word.txt\", \"r\") as f:\n",
    "        non_fake_words = dataframe_helper.string_to_list(f.read())\n",
    "\n",
    "    fake_words = fake_words[:N]\n",
    "    non_fake_words = non_fake_words[:N]\n",
    "        \n",
    "    # KL one hot encoding\n",
    "    fakeWordOneHot = []\n",
    "    nonFakeWordOneHot = []\n",
    "\n",
    "    for content in df['reviewContent']:\n",
    "        fakeOneHot = ''\n",
    "        nonFakeOneHot = ''\n",
    "        words = re.findall(r'\\b[A-Za-z][a-z]{2,9}\\b', content)\n",
    "        words = Counter(words)\n",
    "        for word in fake_words:\n",
    "            if word in words:\n",
    "                fakeOneHot += str(words[word])\n",
    "            else:\n",
    "                fakeOneHot += '0'\n",
    "\n",
    "        for word in non_fake_words:\n",
    "            if word in words:\n",
    "                nonFakeOneHot += str(words[word])\n",
    "            else:\n",
    "                nonFakeOneHot += '0'\n",
    "                \n",
    "        fakeWordOneHot.append(fakeOneHot)\n",
    "        nonFakeWordOneHot.append(nonFakeOneHot)\n",
    "    \n",
    "    result = pd.DataFrame()\n",
    "    result['fakeWordsOneHot'] = fakeWordOneHot\n",
    "    result['nonFakeWordsOneHot'] = nonFakeWordOneHot\n",
    "\n",
    "    result = dataframe_helper.onehot(result, 'fakeWordsOneHot', fake_words, 'fake')\n",
    "    result = dataframe_helper.onehot(result, 'nonFakeWordsOneHot', non_fake_words, 'non fake')\n",
    "    \n",
    "    result['reviewContent'] = df['reviewContent']\n",
    "    result['flagged'] = df['flagged']\n",
    "\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering_cVect(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    cVect = CountVectorizer(stop_words='english', preprocessor=preprocess_text, token_pattern = '[a-zA-Z0-9]+')\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=11)\n",
    "    # cVect = CountVectorizer()\n",
    "    cVect.fit(df['reviewContent'].iloc[:8*len(df)//10])\n",
    "    dtv = cVect.transform(df['reviewContent'])\n",
    "    dtv = dtv.toarray()\n",
    "    result =  pd.DataFrame(dtv, columns = [f'{colunm}' for colunm in cVect.get_feature_names()])\n",
    "    result['reviewContent'] = df['reviewContent']\n",
    "    result['flagged'] = df['flagged']\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering_tfidfVect(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    tfidfVect = CountVectorizer(stop_words='english', preprocessor=preprocess_text, token_pattern = '[a-zA-Z0-9]+')\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=11)\n",
    "    # tfidfVect = CountVectorizer()\n",
    "    tfidfVect.fit(df['reviewContent'].iloc[:8*len(df)//10])\n",
    "    dtv = tfidfVect.transform(df['reviewContent'])\n",
    "    dtv = dtv.toarray()\n",
    "    result =  pd.DataFrame(dtv, columns = [f'{colunm}' for colunm in tfidfVect.get_feature_names()])\n",
    "    result['reviewContent'] = df['reviewContent']\n",
    "    result['flagged'] = df['flagged']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering_combine(df:pd.DataFrame, N:int = None) -> pd.DataFrame:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    with open(\"../Data/top_word/top_fake_word.txt\", \"r\") as f:\n",
    "        fake_words = dataframe_helper.string_to_list(f.read())\n",
    "\n",
    "    with open(\"../Data/top_word/top_genuine_word.txt\", \"r\") as f:\n",
    "        non_fake_words = dataframe_helper.string_to_list(f.read())\n",
    "\n",
    "    fake_words = fake_words[:N]\n",
    "    non_fake_words = non_fake_words[:N]\n",
    "        \n",
    "    # KL one hot encoding\n",
    "    fakeWordOneHot = []\n",
    "    nonFakeWordOneHot = []\n",
    "\n",
    "    # linguistic features\n",
    "    number_of_words = []\n",
    "    number_of_verbs = []\n",
    "    number_of_clauses = []\n",
    "    average_word_length = []\n",
    "    pausality = []\n",
    "    number_of_passive_voice = []\n",
    "    number_of_self_and_group_reference_terms_used = []\n",
    "    expressiveness_ratio = []\n",
    "    lexical_diversity = []\n",
    "    content_word_diversity = []\n",
    "    typo_ratio = []\n",
    "    number_of_spatio_temporal_words = []\n",
    "    \n",
    "    for content in df['reviewContent']:\n",
    "        fakeOneHot = ''\n",
    "        nonFakeOneHot = ''\n",
    "        words = re.findall(r'\\b[A-Za-z][a-z]{2,9}\\b', content)\n",
    "\n",
    "        for word in fake_words:\n",
    "            if word in words:\n",
    "                fakeOneHot += '1'\n",
    "            else:\n",
    "                fakeOneHot += '0'\n",
    "\n",
    "        for word in non_fake_words:\n",
    "            if word in words:\n",
    "                nonFakeOneHot += '1'\n",
    "            else:\n",
    "                nonFakeOneHot += '0'\n",
    "                \n",
    "        fakeWordOneHot.append(fakeOneHot)\n",
    "        nonFakeWordOneHot.append(nonFakeOneHot)\n",
    "        \n",
    "        doc = nlp(content)\n",
    "        if len(doc) != 0:\n",
    "            number_of_words.append(len(doc))\n",
    "            number_of_verbs.append(len([token for token in doc if token.pos_ == \"VERB\"]))\n",
    "            number_of_clauses.append(len([token for token in doc if token.dep_ == \"ROOT\"]))\n",
    "            average_word_length.append(sum([len(token) for token in doc]) / len(doc))\n",
    "            pausality.append(len([token for token in doc if token.pos_ == \"PUNCT\"]) / len(doc))\n",
    "            number_of_passive_voice.append(len([token for token in doc if token.dep_ == \"nsubjpass\"]))\n",
    "            number_of_self_and_group_reference_terms_used.append(len([token for token in doc if token.dep_ == \"nsubj\"]))\n",
    "            expressiveness_ratio.append(len([token for token in doc if token.pos_ == \"ADJ\"]) / len(doc))\n",
    "            lexical_diversity.append(len(set([token.text for token in doc])) / len(doc))\n",
    "            content_word_diversity.append(len(set([token.text for token in doc if token.pos_ != \"PUNCT\"])) / len(doc))\n",
    "            typo_ratio.append(len([token for token in doc if token.pos_ == \"SYM\"]) / len(doc))\n",
    "            number_of_spatio_temporal_words.append(len([token for token in doc if token.pos_ == \"ADV\"]))\n",
    "        else:\n",
    "            number_of_words.append(0)\n",
    "            number_of_verbs.append(0)\n",
    "            number_of_clauses.append(0)\n",
    "            average_word_length.append(0)\n",
    "            pausality.append(0)\n",
    "            number_of_passive_voice.append(0)\n",
    "            number_of_self_and_group_reference_terms_used.append(0)\n",
    "            expressiveness_ratio.append(0)\n",
    "            lexical_diversity.append(0)\n",
    "            content_word_diversity.append(0)\n",
    "            typo_ratio.append(0)\n",
    "            number_of_spatio_temporal_words.append(0)\n",
    "\n",
    "    result = pd.DataFrame()\n",
    "    result['fakeWordsOneHot'] = fakeWordOneHot\n",
    "    result['nonFakeWordsOneHot'] = nonFakeWordOneHot\n",
    "    result = dataframe_helper.onehot(result, 'fakeWordsOneHot', fake_words, 'fake')\n",
    "    result = dataframe_helper.onehot(result, 'nonFakeWordsOneHot', non_fake_words, 'non fake')\n",
    "    result['number_of_words'] = number_of_words\n",
    "    result['number_of_verbs'] = number_of_verbs\n",
    "    result['number_of_clauses'] = number_of_clauses\n",
    "    result['average_word_length'] = average_word_length\n",
    "    result['pausality'] = pausality\n",
    "    result['number_of_passive_voice'] = number_of_passive_voice\n",
    "    result['number_of_self_and_group_reference_terms_used'] = number_of_self_and_group_reference_terms_used\n",
    "    result['expressiveness_ratio'] = expressiveness_ratio\n",
    "    result['lexical_diversity'] = lexical_diversity\n",
    "    result['content_word_diversity'] = content_word_diversity\n",
    "    result['typo_ratio'] = typo_ratio\n",
    "    result['number_of_spatio_temporal_words'] = number_of_spatio_temporal_words  \n",
    "\n",
    "    result['reviewContent'] = df['reviewContent']\n",
    "    result['flagged'] = df['flagged']\n",
    "\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering_linguistic(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "    number_of_words = []\n",
    "    number_of_verbs = []\n",
    "    number_of_clauses = []\n",
    "    average_word_length = []\n",
    "    pausality = []\n",
    "    number_of_passive_voice = []\n",
    "    number_of_self_and_group_reference_terms_used = []\n",
    "    expressiveness_ratio = []\n",
    "    lexical_diversity = []\n",
    "    content_word_diversity = []\n",
    "    typo_ratio = []\n",
    "    number_of_spatio_temporal_words = []\n",
    "    \n",
    "    for content in df['reviewContent']:\n",
    "        doc = nlp(content)\n",
    "        if len(doc) != 0:\n",
    "            number_of_words.append(len(doc))\n",
    "            number_of_verbs.append(len([token for token in doc if token.pos_ == \"VERB\"]))\n",
    "            number_of_clauses.append(len([token for token in doc if token.dep_ == \"ROOT\"]))\n",
    "            average_word_length.append(sum([len(token) for token in doc]) / len(doc))\n",
    "            pausality.append(len([token for token in doc if token.pos_ == \"PUNCT\"]) / len(doc))\n",
    "            number_of_passive_voice.append(len([token for token in doc if token.dep_ == \"nsubjpass\"]))\n",
    "            number_of_self_and_group_reference_terms_used.append(len([token for token in doc if token.dep_ == \"nsubj\"]))\n",
    "            expressiveness_ratio.append(len([token for token in doc if token.pos_ == \"ADJ\"]) / len(doc))\n",
    "            lexical_diversity.append(len(set([token.text for token in doc])) / len(doc))\n",
    "            content_word_diversity.append(len(set([token.text for token in doc if token.pos_ != \"PUNCT\"])) / len(doc))\n",
    "            typo_ratio.append(len([token for token in doc if token.pos_ == \"SYM\"]) / len(doc))\n",
    "            number_of_spatio_temporal_words.append(len([token for token in doc if token.pos_ == \"ADV\"]))\n",
    "        else:\n",
    "            number_of_words.append(0)\n",
    "            number_of_verbs.append(0)\n",
    "            number_of_clauses.append(0)\n",
    "            average_word_length.append(0)\n",
    "            pausality.append(0)\n",
    "            number_of_passive_voice.append(0)\n",
    "            number_of_self_and_group_reference_terms_used.append(0)\n",
    "            expressiveness_ratio.append(0)\n",
    "            lexical_diversity.append(0)\n",
    "            content_word_diversity.append(0)\n",
    "            typo_ratio.append(0)\n",
    "            number_of_spatio_temporal_words.append(0)\n",
    "\n",
    "    result = pd.DataFrame()\n",
    "    result['number_of_words'] = number_of_words\n",
    "    result['number_of_verbs'] = number_of_verbs\n",
    "    result['number_of_clauses'] = number_of_clauses\n",
    "    result['average_word_length'] = average_word_length\n",
    "    result['pausality'] = pausality\n",
    "    result['number_of_passive_voice'] = number_of_passive_voice\n",
    "    result['number_of_self_and_group_reference_terms_used'] = number_of_self_and_group_reference_terms_used\n",
    "    result['expressiveness_ratio'] = expressiveness_ratio\n",
    "    result['lexical_diversity'] = lexical_diversity\n",
    "    result['content_word_diversity'] = content_word_diversity\n",
    "    result['typo_ratio'] = typo_ratio\n",
    "    result['number_of_spatio_temporal_words'] = number_of_spatio_temporal_words  \n",
    "    result['reviewContent'] = df['reviewContent']\n",
    "    result['flagged'] = df['flagged']\n",
    "\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframe_helper.load_data()\n",
    "df = dataframe_helper.data_cleaning(df)\n",
    "# df = feature_engineering_one_hot_cvect(df)\n",
    "# df = feature_engineering_cVect(df)\n",
    "# df = feature_engineering_one_hot(df)\n",
    "# df = feature_engineering_word_count(df)\n",
    "# df = feature_engineering_count_by_word(df,50)\n",
    "# df = feature_engineering_linguistic(df)\n",
    "# df = feature_engineering_combine(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# over_sampling_df = dataframe_helper.over_sampling(df=df, target='flagged')\n",
    "# under_sampling_df = dataframe_helper.under_sampling(df=df, target='flagged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over-Sampling Data\n",
      "Over-Sampling Complete\n"
     ]
    }
   ],
   "source": [
    "over_sampling_df = dataframe_helper.over_sampling(df=df, target='flagged')\n",
    "over_sampling_df = feature_engineering_cVect(over_sampling_df)\n",
    "flagged = over_sampling_df['flagged'] \n",
    "reviewContent = over_sampling_df['reviewContent']\n",
    "over_sampling_df = over_sampling_df.drop(['reviewContent', 'flagged'], axis=1)\n",
    "over_sampling_df = over_sampling_df.astype(int)\n",
    "over_sampling_df = over_sampling_df.apply(lambda x: x/x)\n",
    "over_sampling_df = over_sampling_df.fillna(0)\n",
    "over_sampling_df['flagged'] = flagged\n",
    "over_sampling_df['reviewContent'] = reviewContent\n",
    "\n",
    "# under_sampling_df = dataframe_helper.under_sampling(df=df, target='flagged')\n",
    "# under_sampling_df = feature_engineering_cVect(under_sampling_df)\n",
    "# flagged = under_sampling_df['flagged'] \n",
    "# reviewContent = under_sampling_df['reviewContent']\n",
    "# under_sampling_df = under_sampling_df.drop(['reviewContent', 'flagged'], axis=1)\n",
    "# under_sampling_df = under_sampling_df.astype(int)\n",
    "# under_sampling_df = under_sampling_df.apply(lambda x: x/x)\n",
    "# under_sampling_df = under_sampling_df.fillna(0)\n",
    "# under_sampling_df['flagged'] = flagged\n",
    "# under_sampling_df['reviewContent'] = reviewContent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_sampling_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42, criterion='entropy', max_depth=14, max_features='auto', n_estimators=500)\n",
    "lr = LogisticRegression(solver='liblinear', penalty ='l2' , C = 2.0)\n",
    "nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.supervised_learning(over_sampling_df.copy(), model=rf, algorithm='Random Forest', drop_column='reviewContent', target_column='flagged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.supervised_learning(over_sampling_df.copy(), model=nb, algorithm='Naive Bayes', drop_column='reviewContent', target_column='flagged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression Model\n",
      "Logistic Regression Model Results\n",
      "----------------------------------------\n",
      "Accuracy Score : 0.8275828835774865\n",
      "Precision Score : 0.7732288501519271\n",
      "Recall Score : 0.928736073761045\n",
      "F1 Score : 0.8438781743607645\n",
      "Confusion Matrix : \n",
      "[[3752 1418]\n",
      " [ 371 4835]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning.supervised_learning(over_sampling_df.copy(), model=lr, algorithm='Logistic Regression', drop_column='reviewContent', target_column='flagged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.semi_supervised_learning(over_sampling_df.copy(), experiment_name, df_type='over_sampled', model=rf, threshold=0.7, iterations=7, algorithm='Random Forest', target_column='flagged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.semi_supervised_learning(over_sampling_df.copy(), experiment_name, df_type='over_sampled', model=nb, threshold=0.7, iterations=7, algorithm='Naive Bayes', target_column='flagged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.semi_supervised_learning(over_sampling_df.copy(), experiment_name, df_type='over_sampled', model=lr, threshold=0.7, iterations=7, algorithm='Logistic Regression', target_column='flagged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.supervised_learning(under_sampling_df.copy(), model=rf, algorithm='Random Forest', drop_column='reviewContent', target_column='flagged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.supervised_learning(under_sampling_df.copy(), model=nb, algorithm='Naive Bayes', drop_column='reviewContent', target_column='flagged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.supervised_learning(under_sampling_df.copy() , model=lr, algorithm='Logistic Regression', drop_column='reviewContent', target_column='flagged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.semi_supervised_learning(under_sampling_df.copy(), experiment_name, df_type='over_sampled', model=rf, threshold=0.7, iterations=7, algorithm='Random Forest', target_column='flagged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.semi_supervised_learning(under_sampling_df.copy(), experiment_name, df_type='over_sampled', model=nb, threshold=0.7, iterations=7, algorithm='Naive Bayes', target_column='flagged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.semi_supervised_learning(under_sampling_df.copy(), experiment_name, df_type='over_sampled', model=lr, threshold=0.7, iterations=7, algorithm='Logistic Regression', target_column='flagged')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d2032d7104da15a9d10fd1a2c136158f111ee2ad9d0f9c669774920547ee53a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
